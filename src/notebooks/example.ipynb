{
 "cells": [
  {
   "cell_type": "code",
   "id": "2d06bcae3c2d6e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T23:40:36.193978Z",
     "start_time": "2025-06-18T23:40:36.191272Z"
    }
   },
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.0 (v3.13.0:60403a5409f, Oct  7 2024, 00:37:40) [Clang 15.0.0 (clang-1500.3.9.4)]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e9cbd2def25c5abb"
  },
  {
   "cell_type": "markdown",
   "id": "c2b29e305159577c",
   "metadata": {},
   "source": [
    "# Autodiff Library Testing Notebook\n",
    "This notebook tests the C++ autodiff library with Python bindings.\n",
    "## Setup\n",
    "Make sure you've built the module using either:\n",
    "- CMake: `cmake .. && make autodiff` from build directory\n",
    "- pip: `pip install -e .` from this directory"
   ]
  },
  {
   "cell_type": "code",
   "id": "64447a87b392231f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T23:40:39.000728Z",
     "start_time": "2025-06-18T23:40:38.995191Z"
    }
   },
   "source": [
    "try:\n",
    "    import autodiff\n",
    "    print(\"✅ Autodiff module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Failed to import autodiff module: {e}\")\n",
    "    print(\"Make sure you've built the module first.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to import autodiff module: dlopen(/Users/duque/Projects/Differential-Calculus/Gradient-Descent/src/notebooks/autodiff.cpython-313-darwin.so, 0x0002): symbol not found in flat namespace '__ZN8autodiffmlERKNSt3__110shared_ptrINS_8VariableEEEd'\n",
      "Make sure you've built the module first.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "6dc0ba1c6745b021",
   "metadata": {},
   "source": [
    "## Basic Operations Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4be1f6a6d0f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables\n",
    "x = autodiff.Variable.create(2.0, True)\n",
    "y = autodiff.Variable.create(3.0, True)\n",
    "\n",
    "print(f\"x = {x}\")\n",
    "print(f\"y = {y}\")\n",
    "print(f\"x.value = {x.value}\")\n",
    "print(f\"y.value = {y.value}\")\n",
    "print(f\"x.requires_grad = {x.requires_grad}\")\n",
    "print(f\"y.requires_grad = {y.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd583ea0e9c379c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T23:22:40.342608Z",
     "start_time": "2025-06-18T23:22:39.622451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to import autodiff module: No module named 'autodiff'\n",
      "Make sure you've built the module first.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'autodiff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 26\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMake sure you\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mve built the module first.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# %% [markdown]\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# ## Basic Operations Test\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# %%\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Create variables\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mautodiff\u001B[49m\u001B[38;5;241m.\u001B[39mVariable\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m2.0\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     27\u001B[0m y \u001B[38;5;241m=\u001B[39m autodiff\u001B[38;5;241m.\u001B[39mVariable\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m3.0\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'autodiff' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Test arithmetic operations\n",
    "print(\"=== Arithmetic Operations ===\")\n",
    "\n",
    "z_add = x + y\n",
    "z_sub = x - y\n",
    "z_mul = x * y\n",
    "z_div = x / y\n",
    "z_neg = -x\n",
    "\n",
    "print(f\"x + y = {z_add} (value: {z_add.value})\")\n",
    "print(f\"x - y = {z_sub} (value: {z_sub.value})\")\n",
    "print(f\"x * y = {z_mul} (value: {z_mul.value})\")\n",
    "print(f\"x / y = {z_div} (value: {z_div.value:.6f})\")\n",
    "print(f\"-x = {z_neg} (value: {z_neg.value})\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Scalar Operations Test\n",
    "\n",
    "# %%\n",
    "print(\"=== Operations with Scalars ===\")\n",
    "\n",
    "x = autodiff.Variable.create(5.0, True)\n",
    "\n",
    "y1 = x + 2.0\n",
    "y2 = 3.0 + x\n",
    "y3 = x * 2.0\n",
    "y4 = 4.0 * x\n",
    "y5 = x - 1.0\n",
    "y6 = 10.0 - x\n",
    "y7 = x / 2.0\n",
    "y8 = 20.0 / x\n",
    "\n",
    "print(f\"x = {x.value}\")\n",
    "print(f\"x + 2 = {y1.value}\")\n",
    "print(f\"3 + x = {y2.value}\")\n",
    "print(f\"x * 2 = {y3.value}\")\n",
    "print(f\"4 * x = {y4.value}\")\n",
    "print(f\"x - 1 = {y5.value}\")\n",
    "print(f\"10 - x = {y6.value}\")\n",
    "print(f\"x / 2 = {y7.value}\")\n",
    "print(f\"20 / x = {y8.value}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Mathematical Functions Test\n",
    "\n",
    "# %%\n",
    "import math\n",
    "\n",
    "print(\"=== Mathematical Functions ===\")\n",
    "\n",
    "x = autodiff.Variable.create(1.0, True)\n",
    "\n",
    "exp_x = x.exp()\n",
    "log_x = x.log()\n",
    "sin_x = x.sin()\n",
    "cos_x = x.cos()\n",
    "tanh_x = x.tanh()\n",
    "\n",
    "print(f\"x = {x.value}\")\n",
    "print(f\"exp(x) = {exp_x.value:.6f} (expected: {math.exp(1.0):.6f})\")\n",
    "print(f\"log(x) = {log_x.value:.6f} (expected: {math.log(1.0):.6f})\")\n",
    "print(f\"sin(x) = {sin_x.value:.6f} (expected: {math.sin(1.0):.6f})\")\n",
    "print(f\"cos(x) = {cos_x.value:.6f} (expected: {math.cos(1.0):.6f})\")\n",
    "print(f\"tanh(x) = {tanh_x.value:.6f} (expected: {math.tanh(1.0):.6f})\")\n",
    "\n",
    "# %%\n",
    "# Test power function\n",
    "print(\"=== Power Functions ===\")\n",
    "\n",
    "x = autodiff.Variable.create(2.0, True)\n",
    "y = autodiff.Variable.create(3.0, True)\n",
    "\n",
    "pow_xy = x.pow(y)\n",
    "print(f\"x^y = {x.value}^{y.value} = {pow_xy.value}\")\n",
    "\n",
    "pow_x2 = x ** 2.0\n",
    "print(f\"x^2 = {x.value}^2 = {pow_x2.value}\")\n",
    "\n",
    "pow_2x = autodiff.pow(2.0, x)\n",
    "print(f\"2^x = 2^{x.value} = {pow_2x.value}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Gradient Computation Tests\n",
    "\n",
    "# %%\n",
    "print(\"=== Simple Gradient Test ===\")\n",
    "\n",
    "x = autodiff.Variable.create(3.0, True)\n",
    "f = x * x\n",
    "\n",
    "print(f\"f(x) = x^2\")\n",
    "print(f\"x = {x.value}\")\n",
    "print(f\"f(x) = {f.value}\")\n",
    "\n",
    "f.backward()\n",
    "print(f\"df/dx = {x.grad} (expected: 2*{x.value} = {2*x.value})\")\n",
    "\n",
    "x.zero_grad()\n",
    "print(f\"After zero_grad(): x.grad = {x.grad}\")\n",
    "\n",
    "# %%\n",
    "print(\"=== Multi-variable Gradient Test ===\")\n",
    "\n",
    "x = autodiff.Variable.create(3.0, True)\n",
    "y = autodiff.Variable.create(4.0, True)\n",
    "\n",
    "f = x * x + 2.0 * x * y + y * y\n",
    "\n",
    "print(f\"f(x, y) = x^2 + 2*x*y + y^2\")\n",
    "print(f\"x = {x.value}, y = {y.value}\")\n",
    "print(f\"f({x.value}, {y.value}) = {f.value}\")\n",
    "\n",
    "f.backward()\n",
    "\n",
    "expected_df_dx = 2*x.value + 2*y.value\n",
    "expected_df_dy = 2*x.value + 2*y.value\n",
    "\n",
    "print(f\"df/dx = {x.grad} (expected: {expected_df_dx})\")\n",
    "print(f\"df/dy = {y.grad} (expected: {expected_df_dy})\")\n",
    "\n",
    "# %%\n",
    "print(\"=== Mathematical Function Gradients ===\")\n",
    "\n",
    "x = autodiff.Variable.create(math.pi/4, True)\n",
    "f = x.sin()\n",
    "\n",
    "print(f\"f(x) = sin(x)\")\n",
    "print(f\"x = π/4 = {x.value:.6f}\")\n",
    "print(f\"f(π/4) = {f.value:.6f}\")\n",
    "\n",
    "f.backward()\n",
    "expected_grad = math.cos(x.value)\n",
    "print(f\"df/dx = {x.grad:.6f} (expected: cos(π/4) = {expected_grad:.6f})\")\n",
    "\n",
    "x.zero_grad()\n",
    "x.set_value(1.0)\n",
    "f = x.exp()\n",
    "\n",
    "print(f\"\\nf(x) = exp(x)\")\n",
    "print(f\"x = {x.value}\")\n",
    "print(f\"f(1) = {f.value:.6f}\")\n",
    "\n",
    "f.backward()\n",
    "expected_grad = math.exp(x.value)\n",
    "print(f\"df/dx = {x.grad:.6f} (expected: exp(1) = {expected_grad:.6f})\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Complex Function Test\n",
    "\n",
    "# %%\n",
    "print(\"=== Complex Function Test ===\")\n",
    "\n",
    "x = autodiff.Variable.create(0.5, True)\n",
    "y = autodiff.Variable.create(1.0, True)\n",
    "\n",
    "xy = x * y\n",
    "exp_xy = xy.exp()\n",
    "sin_x = x.sin()\n",
    "cos_y = y.cos()\n",
    "sin_cos = sin_x * cos_y\n",
    "f = exp_xy + sin_cos\n",
    "\n",
    "print(f\"f(x, y) = exp(x*y) + sin(x)*cos(y)\")\n",
    "print(f\"x = {x.value}, y = {y.value}\")\n",
    "print(f\"f({x.value}, {y.value}) = {f.value:.6f}\")\n",
    "\n",
    "f.backward()\n",
    "\n",
    "print(f\"df/dx = {x.grad:.6f}\")\n",
    "print(f\"df/dy = {y.grad:.6f}\")\n",
    "\n",
    "expected_df_dx = y.value * math.exp(x.value * y.value) + math.cos(x.value) * math.cos(y.value)\n",
    "expected_df_dy = x.value * math.exp(x.value * y.value) - math.sin(x.value) * math.sin(y.value)\n",
    "\n",
    "print(f\"Expected df/dx = {expected_df_dx:.6f}\")\n",
    "print(f\"Expected df/dy = {expected_df_dy:.6f}\")\n",
    "print(f\"Error in df/dx = {abs(x.grad - expected_df_dx):.8f}\")\n",
    "print(f\"Error in df/dy = {abs(y.grad - expected_df_dy):.8f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Performance Test\n",
    "\n",
    "# %%\n",
    "import time\n",
    "\n",
    "print(\"=== Performance Test ===\")\n",
    "\n",
    "def benchmark_function(n_iterations=1000):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        x = autodiff.Variable.create(0.5 + i * 0.001, True)\n",
    "        y = autodiff.Variable.create(1.0 + i * 0.001, True)\n",
    "\n",
    "        x_sq = x * x\n",
    "        y_sq = y * y\n",
    "        sum_sq = x_sq + y_sq\n",
    "        exp_x = x.exp()\n",
    "        term1 = sum_sq * exp_x\n",
    "        xy = x * y\n",
    "        sin_xy = xy.sin()\n",
    "        f = term1 + sin_xy\n",
    "\n",
    "        f.backward()\n",
    "\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "n_iter = 1000\n",
    "elapsed = benchmark_function(n_iter)\n",
    "print(f\"Computed {n_iter} forward+backward passes in {elapsed:.4f} seconds\")\n",
    "print(f\"Average time per iteration: {elapsed/n_iter*1000:.4f} ms\")\n",
    "print(f\"Iterations per second: {n_iter/elapsed:.0f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Visualization Test (Optional)\n",
    "#\n",
    "# Let's plot a function and its gradient to visualize the autodiff results.\n",
    "\n",
    "# %%\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    def evaluate_function_and_gradient(x_val):\n",
    "        x = autodiff.Variable.create(x_val, True)\n",
    "        x_sq = x * x\n",
    "        x_cubed = x_sq * x\n",
    "        term1 = x_cubed\n",
    "        term2 = 2.0 * x_sq\n",
    "        term3 = x\n",
    "        f = term1 - term2 + term3\n",
    "        f.backward()\n",
    "        return f.value, x.grad\n",
    "\n",
    "    x_vals = np.linspace(-2, 3, 100)\n",
    "    f_vals = []\n",
    "    grad_vals = []\n",
    "\n",
    "    for x_val in x_vals:\n",
    "        f_val, grad_val = evaluate_function_and_gradient(x_val)\n",
    "        f_vals.append(f_val)\n",
    "        grad_vals.append(grad_val)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    ax1.plot(x_vals, f_vals, 'b-', linewidth=2, label='f(x) = x³ - 2x² + x')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylabel('f(x)')\n",
    "    ax1.set_title('Function and its Gradient (computed via Autodiff)')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(x_vals, grad_vals, 'r-', linewidth=2, label=\"f'(x) = 3x² - 4x + 1\")\n",
    "    ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel(\"f'(x)\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"✅ Visualization completed successfully!\")\n",
    "except ImportError:\n",
    "    print(\"📊 Matplotlib not available for visualization. Install with: pip install matplotlib\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Visualization failed: {e}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Summary\n",
    "#\n",
    "# This notebook tested the following features of the autodiff library:\n",
    "#\n",
    "# ✅ **Basic Operations**: Addition, subtraction, multiplication, division, negation\n",
    "# ✅ **Scalar Operations**: Operations between Variables and Python floats\n",
    "# ✅ **Mathematical Functions**: exp, log, sin, cos, tanh, pow\n",
    "# ✅ **Gradient Computation**: Forward and backward passes\n",
    "# ✅ **Multi-variable Functions**: Functions with multiple inputs\n",
    "# ✅ **Complex Expressions**: Nested operations and function compositions\n",
    "# ✅ **Performance**: Timing tests for computational efficiency\n",
    "# ✅ **Visualization**: Plotting functions and their gradients\n",
    "#\n",
    "# The autodiff library appears to be working correctly! 🎉\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
